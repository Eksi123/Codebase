{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d3afa0c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-08-29T08:34:48.059538Z",
     "iopub.status.busy": "2022-08-29T08:34:48.058591Z",
     "iopub.status.idle": "2022-08-29T08:34:48.065949Z",
     "shell.execute_reply": "2022-08-29T08:34:48.065045Z",
     "shell.execute_reply.started": "2022-08-29T08:34:48.059480Z"
    },
    "papermill": {
     "duration": 0.013894,
     "end_time": "2022-08-30T22:58:09.459150",
     "exception": false,
     "start_time": "2022-08-30T22:58:09.445256",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**This is my fist journey in Machine Learning!**\n",
    "\n",
    "By trandition, I will solve the classic \"Titanic survival\" problem by folowing four steps:\n",
    "\n",
    "1. Import modules and datasets needed\n",
    "2. Do an overview of datasets and a subsequent datasets preprocessing\n",
    "3. Build models and select the better performer\n",
    "4. Use the \"best model\" to do prediction \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*Submission File Format:*\n",
    "\n",
    "*You should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns \n",
    "(beyond PassengerId and Survived) or rows.*\n",
    "\n",
    "*The file should have exactly 2 columns:*\n",
    "\n",
    "*1. PassengerId (sorted in any order)*\n",
    "\n",
    "*2.Survived (contains your binary predictions: 1 for survived, 0 for deceased)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98e464a",
   "metadata": {
    "papermill": {
     "duration": 0.01147,
     "end_time": "2022-08-30T22:58:09.484429",
     "exception": false,
     "start_time": "2022-08-30T22:58:09.472959",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import modules and datasets needed #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b98b1c89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-30T22:58:09.513051Z",
     "iopub.status.busy": "2022-08-30T22:58:09.511828Z",
     "iopub.status.idle": "2022-08-30T22:58:10.928862Z",
     "shell.execute_reply": "2022-08-30T22:58:10.928098Z",
     "shell.execute_reply.started": "2022-08-30T22:38:17.527785Z"
    },
    "papermill": {
     "duration": 1.432913,
     "end_time": "2022-08-30T22:58:10.929049",
     "exception": false,
     "start_time": "2022-08-30T22:58:09.496136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Basical API\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import randint as sp_randint # give the integer random distribution \n",
    "\n",
    "# Sklearn support\n",
    "from sklearn import preprocessing # dataset preprocess\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif # feature selection\n",
    "from sklearn.model_selection import StratifiedKFold # k fold cross-validation\n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# from sklearn.metrics import accuracy_score, f1_score # model metrics\n",
    "from sklearn.linear_model import LogisticRegression # LR model\n",
    "from sklearn.svm import SVC # SVC model\n",
    "from sklearn.neighbors import KNeighborsClassifier # KNC model\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis # LDA model\n",
    "from sklearn.naive_bayes import GaussianNB # GNB model\n",
    "from sklearn.tree import DecisionTreeClassifier # DTC model\n",
    "from sklearn.ensemble import RandomForestClassifier # RFC model\n",
    "\n",
    "# Import \"Titanic-surviviors\" datasets\n",
    "train_df = pd.read_csv('../input/titanic/train.csv')\n",
    "pred_df = pd.read_csv('../input/titanic/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27360c1",
   "metadata": {
    "papermill": {
     "duration": 0.011473,
     "end_time": "2022-08-30T22:58:10.952742",
     "exception": false,
     "start_time": "2022-08-30T22:58:10.941269",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### tips for new kagglers ###\n",
    "\n",
    "1. Before loading and reading the datasets, you must finish your phone verification, or you will get the error:\"No such file in directory\".\n",
    "\n",
    "2. The \"file (train.csv, test.csv, etc.) path\" can be copied .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c952e628",
   "metadata": {
    "papermill": {
     "duration": 0.011392,
     "end_time": "2022-08-30T22:58:10.975931",
     "exception": false,
     "start_time": "2022-08-30T22:58:10.964539",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Do an overview of datasets and a subsequent datasets preprocessing #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "026b629b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-30T22:58:11.009573Z",
     "iopub.status.busy": "2022-08-30T22:58:11.008531Z",
     "iopub.status.idle": "2022-08-30T22:58:11.055618Z",
     "shell.execute_reply": "2022-08-30T22:58:11.056176Z",
     "shell.execute_reply.started": "2022-08-30T22:38:22.018180Z"
    },
    "papermill": {
     "duration": 0.068858,
     "end_time": "2022-08-30T22:58:11.056361",
     "exception": false,
     "start_time": "2022-08-30T22:58:10.987503",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Pclass       418 non-null    int64  \n",
      " 2   Name         418 non-null    object \n",
      " 3   Sex          418 non-null    object \n",
      " 4   Age          332 non-null    float64\n",
      " 5   SibSp        418 non-null    int64  \n",
      " 6   Parch        418 non-null    int64  \n",
      " 7   Ticket       418 non-null    object \n",
      " 8   Fare         417 non-null    float64\n",
      " 9   Cabin        91 non-null     object \n",
      " 10  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.info()\n",
    "train_df.head()\n",
    "\n",
    "pred_df.info()\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425b29ab",
   "metadata": {
    "papermill": {
     "duration": 0.01275,
     "end_time": "2022-08-30T22:58:11.082828",
     "exception": false,
     "start_time": "2022-08-30T22:58:11.070078",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Overview: ###\n",
    "\n",
    "1. The features: \"Name\",\"Sex\",\"Ticket\",\"Cabin\",\"Embarked\" is non-numerical.\n",
    "\n",
    "2. In train_df, the feature \"Cabin\" has a serious missing value problem (only 204 non-null), and \"Age\", \"Embarked\" have a slighter problem (714 and 899 non-null).\n",
    "\n",
    "3. In pred_df, the feature \"Cabin\" has a serious missing value problem (only 91 non-null), and \"Age\", \"Fare\" have a slighter problem (332 and 417 non-null)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10219720",
   "metadata": {
    "papermill": {
     "duration": 0.012414,
     "end_time": "2022-08-30T22:58:11.107892",
     "exception": false,
     "start_time": "2022-08-30T22:58:11.095478",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    " ### Preprocess: ###\n",
    " \n",
    " 1. Drop the features: “PassengerId\",\"Name\",\"Ticket\",\"Cabin\",\"Embarked\",  because \"Name\",\"Ticket\",\"Embarked\" are almostly irrelatively with \"survive or not\", and the \"cabin\" has serious missing value problem in both two datasets.\n",
    " \n",
    " 2. Fullfill missing values of \"Age\" and the noly missing value of \"Fare\" in pred_df by linear regression method.\n",
    " \n",
    " 3. Recode the \"Sex\" (male, female) with number 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f764b3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-30T22:58:11.136689Z",
     "iopub.status.busy": "2022-08-30T22:58:11.136019Z",
     "iopub.status.idle": "2022-08-30T22:58:11.208875Z",
     "shell.execute_reply": "2022-08-30T22:58:11.210097Z",
     "shell.execute_reply.started": "2022-08-30T22:38:26.173940Z"
    },
    "papermill": {
     "duration": 0.089842,
     "end_time": "2022-08-30T22:58:11.210431",
     "exception": false,
     "start_time": "2022-08-30T22:58:11.120589",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop feature\n",
    "train_df = train_df.drop(labels = [\"PassengerId\",\"Name\",\"Ticket\",\"Cabin\",\"Embarked\"], axis = 1)\n",
    "pred_df = pred_df.drop(labels = [\"PassengerId\",\"Name\",\"Ticket\",\"Cabin\",\"Embarked\"], axis = 1)\n",
    "\n",
    "# Recode feature\n",
    "lab_encoder = preprocessing.LabelEncoder().fit([\"male\",\"female\"]) # \"female -> 0 & male -> 1\"\n",
    "train_df[\"Sex\"] = lab_encoder.transform(train_df[\"Sex\"])\n",
    "pred_df[\"Sex\"] = lab_encoder.transform(pred_df[\"Sex\"])\n",
    "\n",
    "# Fullfill feature\n",
    "combine_df = pd.concat([train_df.iloc[:,1:], pred_df.iloc[:,:]], axis = 0)\n",
    "imputer = KNNImputer(n_neighbors=3).fit(combine_df)\n",
    "train_df.iloc[:,1:] = imputer.transform(train_df.iloc[:,1:])\n",
    "pred_df.iloc[:,:] = imputer.transform(pred_df.iloc[:,:])\n",
    "\n",
    "# alter the type of features\n",
    "train_df[\"Survived\"] = train_df[\"Survived\"].astype(\"int\")\n",
    "train_df[\"Pclass\"] = train_df[\"Pclass\"].astype(\"object\")\n",
    "train_df[\"Sex\"] = train_df[\"Sex\"].astype(\"object\")\n",
    "train_df[\"Parch\"] = train_df[\"Parch\"].astype(\"object\")\n",
    "\n",
    "pred_df[\"Pclass\"] = pred_df[\"Pclass\"].astype(\"object\")\n",
    "pred_df[\"Sex\"] = pred_df[\"Sex\"].astype(\"object\")\n",
    "pred_df[\"Parch\"] = pred_df[\"Parch\"].astype(\"object\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4554df8",
   "metadata": {
    "papermill": {
     "duration": 0.030716,
     "end_time": "2022-08-30T22:58:11.272398",
     "exception": false,
     "start_time": "2022-08-30T22:58:11.241682",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Build models and select the better performer #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22005d7d",
   "metadata": {
    "papermill": {
     "duration": 0.015607,
     "end_time": "2022-08-30T22:58:11.319255",
     "exception": false,
     "start_time": "2022-08-30T22:58:11.303648",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee304395",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-30T22:58:11.358162Z",
     "iopub.status.busy": "2022-08-30T22:58:11.357258Z",
     "iopub.status.idle": "2022-08-30T22:58:17.079114Z",
     "shell.execute_reply": "2022-08-30T22:58:17.078551Z",
     "shell.execute_reply.started": "2022-08-30T22:39:35.868440Z"
    },
    "papermill": {
     "duration": 5.747242,
     "end_time": "2022-08-30T22:58:17.079266",
     "exception": false,
     "start_time": "2022-08-30T22:58:11.332024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 764, in _logistic_regression_path\n",
      "    extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/utils/optimize.py\", line 243, in _check_optimize_result\n",
      "    ).format(solver, result.status, result.message.decode(\"latin1\"))\n",
      "AttributeError: 'str' object has no attribute 'decode'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 764, in _logistic_regression_path\n",
      "    extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/utils/optimize.py\", line 243, in _check_optimize_result\n",
      "    ).format(solver, result.status, result.message.decode(\"latin1\"))\n",
      "AttributeError: 'str' object has no attribute 'decode'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for models:\n",
      "LogisticRegression: nan\n",
      "SVC: 0.68\n",
      "KNeighborsClassifier: 0.69\n",
      "LinearDiscriminantAnalysis: 0.79\n",
      "GaussianNB: 0.79\n",
      "DecisionTreeClassifier: 0.77\n",
      "RandomForestClassifier: 0.82\n",
      "\n",
      "f1-score for models:\n",
      "LogisticRegression: nan\n",
      "SVC: 0.42\n",
      "KNeighborsClassifier: 0.58\n",
      "LinearDiscriminantAnalysis: 0.72\n",
      "GaussianNB: 0.72\n",
      "DecisionTreeClassifier: 0.7\n",
      "RandomForestClassifier: 0.74\n"
     ]
    }
   ],
   "source": [
    "Model = [LogisticRegression(), SVC(), KNeighborsClassifier(), LinearDiscriminantAnalysis(), GaussianNB(), DecisionTreeClassifier(),  RandomForestClassifier()]\n",
    "Res_acc = []; Res_f1 = []\n",
    "X_df = train_df.iloc[:,1:] # dataset of features (Pclass,Sex,...)\n",
    "Y_df = train_df.iloc[:,0] # dataset of label (Survived)\n",
    "\n",
    "for model in Model:\n",
    "    kfold = StratifiedKFold(n_splits = 10, random_state = 1, shuffle=True)\n",
    "    acc_results = cross_val_score(model, X_df, Y_df, cv = kfold, scoring = 'accuracy')\n",
    "    Res_acc.append(round(acc_results.mean(),2))\n",
    "    f1_results = cross_val_score(model, X_df, Y_df, cv = kfold, scoring = 'f1')\n",
    "    Res_f1.append(round(f1_results.mean(),2))\n",
    "\n",
    "print(\"accuracy for models:\"+\"\\n\"+  \n",
    "\"LogisticRegression: \"+str(Res_acc[0])+\"\\n\"+\n",
    "\"SVC: \"+str(Res_acc[1])+\"\\n\"+\n",
    "\"KNeighborsClassifier: \"+str(Res_acc[2])+\"\\n\"+\n",
    "\"LinearDiscriminantAnalysis: \"+str(Res_acc[3])+\"\\n\"+\n",
    "\"GaussianNB: \"+str(Res_acc[4])+\"\\n\"+\n",
    "\"DecisionTreeClassifier: \"+str(Res_acc[5])+\"\\n\"+\n",
    "\"RandomForestClassifier: \"+str(Res_acc[6])+\"\\n\"\n",
    ")\n",
    "\n",
    "print(\"f1-score for models:\"+\"\\n\"+  \n",
    "\"LogisticRegression: \"+str(Res_f1[0])+\"\\n\"+\n",
    "\"SVC: \"+str(Res_f1[1])+\"\\n\"+\n",
    "\"KNeighborsClassifier: \"+str(Res_f1[2])+\"\\n\"+\n",
    "\"LinearDiscriminantAnalysis: \"+str(Res_f1[3])+\"\\n\"+\n",
    "\"GaussianNB: \"+str(Res_f1[4])+\"\\n\"+\n",
    "\"DecisionTreeClassifier: \"+str(Res_f1[5])+\"\\n\"+\n",
    "\"RandomForestClassifier: \"+str(Res_f1[6])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f1ce1a",
   "metadata": {
    "papermill": {
     "duration": 0.013528,
     "end_time": "2022-08-30T22:58:17.108394",
     "exception": false,
     "start_time": "2022-08-30T22:58:17.094866",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### The results of models evaluation: ###\n",
    "\n",
    "**accuracy for models:**\n",
    "\n",
    "LogisticRegression: nan \n",
    "\n",
    "SVC: 0.68\n",
    "\n",
    "KNeighborsClassifier: 0.69\n",
    "\n",
    "LinearDiscriminantAnalysis: 0.79\n",
    "\n",
    "GaussianNB: 0.79\n",
    "\n",
    "DecisionTreeClassifier: 0.77\n",
    "\n",
    "RandomForestClassifier: 0.81\n",
    "\n",
    "**f1-score for models:**\n",
    "\n",
    "LogisticRegression: nan\n",
    "\n",
    "SVC: 0.42\n",
    "\n",
    "KNeighborsClassifier: 0.58\n",
    "\n",
    "LinearDiscriminantAnalysis: 0.72\n",
    "\n",
    "GaussianNB: 0.72\n",
    "\n",
    "DecisionTreeClassifier: 0.7\n",
    "\n",
    "RandomForestClassifier: 0.74\n",
    "\n",
    "***(fail to compute the accuracy and f1-score of LogisticRegression? I cannot solve it.)***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c44c365b",
   "metadata": {},
   "source": [
    "# Select the best parameters of RandomForestClassifirer #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1976e72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist1 = {\"n_estimators\":sp_randint(1,51),\n",
    "              \"max_depth\": [3,4,5, None],                    \n",
    "              \"max_features\": sp_randint(0, 11),          \n",
    "              \"min_samples_split\": sp_randint(2, 11),    \n",
    "              \"bootstrap\": [True, False],                 \n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "random_search = RandomizedSearchCV(RandomForestClassifier(), param_distributions=param_dist1, n_iter=50, cv=10) # n_iter表示随机搜索20组，cv表示5折交叉验证\n",
    "random_search.fit(X_df, Y_df)\n",
    "print('best parameters:',random_search.best_params_,'\\n','best score:', random_search.best_score_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "045dca22",
   "metadata": {
    "papermill": {
     "duration": 0.013966,
     "end_time": "2022-08-30T22:58:17.136314",
     "exception": false,
     "start_time": "2022-08-30T22:58:17.122348",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Use the \"best model\" to do prediction: #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "117f7e72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-30T22:58:17.168110Z",
     "iopub.status.busy": "2022-08-30T22:58:17.167424Z",
     "iopub.status.idle": "2022-08-30T22:58:17.408772Z",
     "shell.execute_reply": "2022-08-30T22:58:17.408117Z",
     "shell.execute_reply.started": "2022-08-30T22:54:53.049930Z"
    },
    "papermill": {
     "duration": 0.258752,
     "end_time": "2022-08-30T22:58:17.408958",
     "exception": false,
     "start_time": "2022-08-30T22:58:17.150206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 1 0 0 0 0 1 0 0 0 1 0 1 1 0 1 0 0 0 0 1 0 1 0 1 1 1 0 0 0 1 0 1 0 0\n",
      " 0 0 1 0 0 0 1 1 0 1 0 1 1 1 0 1 1 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 1 0 0 0\n",
      " 1 0 0 1 0 1 1 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 1 0 0 1 0 1 1 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0\n",
      " 0 0 1 0 0 1 0 0 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 1 1 0 1 1 0 1\n",
      " 0 1 0 0 0 0 0 1 0 1 0 1 0 0 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 1 0\n",
      " 1 1 1 0 0 1 0 0 0 1 0 0 0 0 1 1 1 1 1 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 1 0\n",
      " 1 0 0 1 0 0 0 0 0 0 1 1 1 0 0 0 1 1 0 0 0 1 0 1 0 0 1 0 1 1 1 1 0 0 0 1 0\n",
      " 0 1 0 0 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0\n",
      " 0 1 1 1 1 0 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "RFC = RandomForestClassifier(\n",
    "                        bootstrap = True,\n",
    "                        criterion = 'gini',\n",
    "                        n_estimators = 20,\n",
    "                        max_depth = None,\n",
    "                        max_features = 2,\n",
    "                        min_samples_split = 10\n",
    ").fit(X_df, Y_df)\n",
    "pred_y = RFC.predict(pred_df)\n",
    "\n",
    "print(pred_y)\n",
    "\n",
    "df = pd.read_csv('../input/titanic/test.csv')\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": df[\"PassengerId\"],\n",
    "        \"Survived\": pred_y\n",
    "    })\n",
    "submission.to_csv('./submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 18.461007,
   "end_time": "2022-08-30T22:58:18.136025",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-08-30T22:57:59.675018",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
